data:
    dataset_type: "cached_threedfront"
    encoding_type: "cached_diffusion_text_cosin_angle_objfeatsnorm_lat32_wocm" # textfix for eval #"cached_diffusion_textfix_cosin_angle_objfeatsnorm_lat32_wocm"
    dataset_directory: "/cluster/balrog/jtang/3d_front_processed/diningrooms_objfeats_32_64"
    annotation_file: "../config/diningroom_threed_front_splits.csv"
    path_to_invalid_scene_ids: "../config/invalid_threed_front_rooms.txt"
    path_to_invalid_bbox_jids: "../config/black_list.txt"
    augmentations: ["fixed_rotations"]
    filter_fn: "threed_front_diningroom"
    train_stats: "dataset_stats.txt"
    room_layout_size: "64,64"
    max_length: 21

network:
    type: "diffusion_scene_layout_ddpm"
    # denoising network
    net_type: "unet1d"

    # concate squarewish layer
    point_dim: 65 #33
    latent_dim: 0
    room_mask_condition: false # not use room_mask 
    text_condition: True
    text_embed_dim: 512
    sample_num_points: 21 # max_length 

    objectness_dim: 0
    class_dim: 25  #24+1
    angle_dim: 2 
    objfeat_dim: 32 #64

    # class condition
    learnable_embedding: true
    instance_condition: true
    instance_emb_dim: 128

    # diffusion config
    diffusion_kwargs:
        schedule_type: 'linear'
        beta_start: 0.0001
        beta_end: 0.02
        time_num: 1000 
        loss_type: 'mse'
        model_mean_type: 'v' #'eps'
        model_var_type: 'fixedsmall'
        loss_separate: true
        # calculate iou loss
        loss_iou: true
        train_stats_file: /cluster/balrog/jtang/3d_front_processed/diningrooms_objfeats_32_64/dataset_stats.txt

    net_kwargs:
        dim: 512
        dim_mults: [1, 1, 1, 1]
        channels: 65 # 33 
        objectness_dim: 0
        class_dim: 25
        angle_dim: 2
        objfeat_dim: 32
        self_condition: true
        context_dim: 0
        instanclass_dim: 128 
        seperate_all: true  # separate all
        text_condition: true
        text_dim: 512

feature_extractor:
    name: "resnet18"
    feature_size: 64
    freeze_bn: true
    input_channels: 1

training:
    splits: ["train", "val"]
    epochs: 150000
    steps_per_epoch: 500
    batch_size: 128
    save_frequency: 2000
    max_grad_norm: 10
    # optimizer
    optimizer: Adam
    weight_decay: 0.0
    # schedule
    schedule: 'step'
    lr: 0.0002
    lr_step: 20000
    lr_decay: 0.5

validation:
    splits: ["test"]
    frequency: 10
    batch_size: 128
    gen_traj: false
    num_step: 100
    gen_gt: false
    gen_prob_map: false

logger:
    type: "wandb"
    project: "diffuscene"
 